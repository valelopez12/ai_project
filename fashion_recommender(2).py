# -*- coding: utf-8 -*-
"""Fashion_Recommender(2).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12uK_x3CGjg8RO5X_lGMqAN5EviFa7xFT

**Loading/Installing Libraries**
"""

! pip install ftfy regex tqdm
! pip install git+https://github.com/openai/CLIP.git

import pandas as pd

import numpy as np
import torch

print("Torch version:", torch.__version__)

import clip

"""**Loading Dataset**"""

# Load the Drive helper and mount
from google.colab import drive
drive.mount('/content/drive')

path='/content/drive/MyDrive/Project_AI/'

ima = pd.read_csv(path + "images.csv", error_bad_lines=False)
ima.head(10)

df = pd.read_csv(path + "styles.csv", error_bad_lines=False)
df['image'] = df.apply(lambda row: str(row['id']) + ".jpg", axis=1)
df = df.reset_index(drop=True)
df.head(10)

"""Merging both datasets"""

df_f = pd.merge(df, ima, left_on='image', right_on='filename')
df_f.reset_index(inplace=True)
df_f.head(10)

df_f = df_f.drop(['masterCategory', 'subCategory','articleType','baseColour','season','year','usage', 'Unnamed: 10', 'Unnamed: 11'], axis=1)
df_f.head(10)

df_f = df_f.dropna()

"""**Subset of Data**"""

len(df_f)

# Select a random subset of 200 images
subset = df_f.sample(n=200)
subset.head(10)

"""**Loading CLIP model**"""

model, preprocess = clip.load("ViT-B/32")
model.cuda().eval()
input_resolution = model.visual.input_resolution
context_length = model.context_length
vocab_size = model.vocab_size

print("Model parameters:", f"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}")
print("Input resolution:", input_resolution)
print("Context length:", context_length)
print("Vocab size:", vocab_size)

device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load("ViT-B/32", device=device)

"""**Extracting Text Feautures**"""

def get_text_features(text):
    with torch.no_grad():
        text = clip.tokenize([text]).to(device)
        text_features = model.encode_text(text)
        return text_features

subset['text_features'] = subset['productDisplayName'].apply(get_text_features)

subset.head(10)

"""**Extracting Image Feautures**"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import requests
from PIL import Image
from io import BytesIO

images = {}

# Iterate over the DataFrame rows
for i, (_, row) in enumerate(subset.iterrows()):
    url = row.link
    response = requests.get(url)
    
    # Check if the response is successful
    if response.status_code == 200:
        try:
            image = Image.open(BytesIO(response.content)).convert("RGB")
            
            if image is not None:
                processed_image = preprocess(image).unsqueeze(0).to(device)
                images[row['id']] = processed_image
            else:
                print(f"Skipped image {row['id']} as it could not be opened.")
        except:
            print(f"Skipped image {row['id']} as it is corrupt or incomplete.")
    else:
        print(f"Skipped image {row['id']} as the URL could not be accessed.")

# Define a function to extract image features from the images
def get_image_features(image):
    with torch.no_grad():
        image_features = model.encode_image(image)
        return image_features

# Apply the function to the images in the dictionary
subset['image_features'] = subset['id'].map(lambda x: get_image_features(images[x]))

subset.head(10)

"""**Inserting Text Description**"""

import torch
import clip
import pandas as pd

# Input the text description
input_text = input("Enter a text description: ")

# Function to calculate text features of an input text description
def calculate_text_features(text):
    with torch.no_grad():
        text = clip.tokenize([text]).to(device)
        text_features = model.encode_text(text)
        return text_features

# Calculate features of the input text
input_text_features = calculate_text_features(input_text)

# Normalize the input text features
input_text_features /= input_text_features.norm(dim=-1, keepdim=True)

# Create a new column for cosine similarities
subset['cosine_similarity'] = None

# Iterate over each entry in the subset DataFrame
for index, row in subset.iterrows():
    # Get the text features of the current entry
    text_features = torch.tensor(row['text_features']).to(device).float()
    
    # Normalize the text features
    text_features /= text_features.norm(dim=-1, keepdim=True)
    
    # Calculate cosine similarity between input text features and current text features
    cosine_similarity = torch.matmul(input_text_features.float(), text_features.T)
    
    # Assign the cosine similarity to the corresponding row in the DataFrame
    subset.at[index, 'cosine_similarity'] = cosine_similarity.item()

# Display the updated DataFrame with cosine similarities
subset.head(10)

# Top 5 Values
subset = subset.sort_values(by='cosine_similarity', ascending=False)
top_5 = subset.head(5)

import requests
from PIL import Image
from io import BytesIO

# Display the top 5 entries with their descriptions and images
for index, row in top_5.iterrows():
    # Get the description
    description = row['productDisplayName']
    
    # Get the image URL
    image_url = row['link']
    
    # Fetch the image
    response = requests.get(image_url)
    image = Image.open(BytesIO(response.content))
    
    # Display the description and image
    print("Description:", description)
    image.show()
    print("--------------------------------------")

"""**Inserting Image Description**"""

import torch
import clip
import pandas as pd
from PIL import Image
import requests
from io import BytesIO


# Input the file path of an image
image_path = path + input("Enter the name of an image (must be in google drive): ")

# Function to calculate image features from an image
def calculate_image_features(image):
    with torch.no_grad():
        image = preprocess(image).unsqueeze(0).to(device)
        image_features = model.encode_image(image)
        return image_features

# Calculate features of the input image
input_image = Image.open(image_path).convert("RGB")
input_image_features = calculate_image_features(input_image)

# Normalize the input image features
input_image_features /= input_image_features.norm(dim=-1, keepdim=True)

# Create a new column for cosine similarities
subset['cosine_similarity'] = None

# Iterate over each entry in the subset DataFrame
for index, row in subset.iterrows():
    # Get the image features of the current entry
    image_features = torch.tensor(row['image_features']).to(device).float()
    
    # Normalize the image features
    image_features /= image_features.norm(dim=-1, keepdim=True)
    
    # Calculate cosine similarity between input image features and current image features
    cosine_similarity = torch.matmul(input_image_features.float(), image_features.T)
    
    # Assign the cosine similarity to the corresponding row in the DataFrame
    subset.at[index, 'cosine_similarity'] = cosine_similarity.item()


subset.head(10)

# Sort the DataFrame by cosine similarity in descending order
subset = subset.sort_values(by='cosine_similarity', ascending=False)
# Extract the top 5 entries
top_5 = subset.head(5)

for index, row in top_5.iterrows():
    # Get the description
    description = row['productDisplayName']
    
    # Get the image URL
    image_url = row['link']
    
    # Fetch the image
    response = requests.get(image_url)
    image = Image.open(BytesIO(response.content))
    
    # Display the description and image
    print("Description:", description)
    image.show()
    print("--------------------------------------")

"""**Scalable Model**
> Works with 40,000 data pieces. Has the same processing as the quick simulation. The main difference is that when determining the cosine similarity of inserting an image (rather than text) it doesn't take into consideration the images of the data set and compares it only to the text. It has been proven effective, however, there would be a limitation that the model is not as accurate. 



"""

# Making a copy of original dataset. 
df_s = df_f
df_s.head(10)

def get_text_features(text):
    with torch.no_grad():
        text = clip.tokenize([text]).to(device)
        text_features = model.encode_text(text)
        return text_features

df_s['text_features'] = df_s['productDisplayName'].apply(get_text_features)

import torch
import clip
import pandas as pd

# Input the text description
input_text = input("Enter a text description: ")

# Function to calculate text features of an input text description
def calculate_text_features(text):
    with torch.no_grad():
        text = clip.tokenize([text]).to(device)
        text_features = model.encode_text(text)
        return text_features

# Calculate features of the input text
input_text_features = calculate_text_features(input_text)

# Normalize the input text features
input_text_features /= input_text_features.norm(dim=-1, keepdim=True)

# Create a new column for cosine similarities
df_s['cosine_similarity'] = None

# Iterate over each entry in the subset DataFrame
for index, row in df_s.iterrows():
    # Get the text features of the current entry
    text_features = torch.tensor(row['text_features']).to(device).float()
    
    # Normalize the text features
    text_features /= text_features.norm(dim=-1, keepdim=True)
    
    # Calculate cosine similarity between input text features and current text features
    cosine_similarity = torch.matmul(input_text_features.float(), text_features.T)
    
    # Assign the cosine similarity to the corresponding row in the DataFrame
    df_s.at[index, 'cosine_similarity'] = cosine_similarity.item()

# Display the updated DataFrame with cosine similarities
df_s.head(10)

import torch
import clip
import pandas as pd
from PIL import Image
import requests
from io import BytesIO


# Input the file path of an image
image_path = path + input("Enter the name of an image (must be in google drive): ")

# Function to calculate image features from an image
def calculate_image_features(image):
    with torch.no_grad():
        image = preprocess(image).unsqueeze(0).to(device)
        image_features = model.encode_image(image)
        return image_features

# Calculate features of the input image
input_image = Image.open(image_path).convert("RGB")
input_image_features = calculate_image_features(input_image)

# Normalize the input image features
input_image_features /= input_image_features.norm(dim=-1, keepdim=True)

# Create a new column for cosine similarities
df_s['cosine_similarity'] = None

# Iterate over each entry in the subset DataFrame
for index, row in df_s.iterrows():
    # Get the text features of the current entry
    text_features = torch.tensor(row['text_features']).to(device).float()
    
    # Normalize the text features
    text_features /= text_features.norm(dim=-1, keepdim=True)
    
    # Calculate cosine similarity between input image features and current image features
    cosine_similarity = torch.matmul(input_image_features.float(), text_features.T)
    
    # Assign the cosine similarity to the corresponding row in the DataFrame
    df_s.at[index, 'cosine_similarity'] = cosine_similarity.item()


df_s.head(10)